{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c00b45-c571-4438-be9b-60f80e8be054",
   "metadata": {},
   "source": [
    "# Fie Upon Thee, Autocorrect!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54dee98-c213-4197-b2eb-8184fa70d7ea",
   "metadata": {},
   "source": [
    "<img src=\"img/shakespeare.jpg\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd8904-0e5d-41bc-98b8-6d56c14eb7db",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8becce69-ae8e-466a-881a-e779deb34f59",
   "metadata": {},
   "source": [
    "## Recap of yesterday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633fc46a-6ac8-465f-a977-1af24a866f58",
   "metadata": {},
   "source": [
    "I'll just leave this here so we can refer back to it.\n",
    "\n",
    "* Quantitative data analysts distinguish between **measurements**, which are direct observations or outcomes of experiments, and **models**, which are mathematical machines that describe, predict, or explain the measurements in a quantitative way.\n",
    "* Measurements can be expressed as points in an **N-dimensional space**. Since the number of measurements is finite, they can't completely fill the space.\n",
    "  * Measurements can be represented in a 2-D data frame or 2-D array, in which the rows are repeated observations or experiments and the columns are observed attributes, one column/dimension per attribute.\n",
    "  * Measurements can be visualized as a `scatter` plot.\n",
    "  * Measurements say what _is_ true.\n",
    "* Models, when questioned, provide a response for any point in the **N-dimensional space**, so a model completely fills the space.\n",
    "  * Models can be represented in an N-dimensional array, as a value for each point in space, or as a function that returns a response for N arguments.\n",
    "  * Models can be visualized by coloring a space with `imshow` or `contourf`, or with contour lines (like mountains on an elevation map).\n",
    "  * The model-function's response may be\n",
    "    * the probability that that combination of attributes exists, or\n",
    "    * a prediction of some other attribute (or its probability), or\n",
    "    * a category that we use to organize the data but isn't directly measurable, such as species (or its probability).\n",
    "  * Models say what _would be_ true, under the given conditions, assuming that the model is accurate, etc.\n",
    "* Models are algorithms involving numerical and categorical values: changing these values changes the model.\n",
    "  * **Parameters** are values that we tune in an automated **fitting** procedure to find the best model for some measurements.\n",
    "  * **Hyperparameters** are not part of the fitting procedure, but also impact the quality of the fitted model.\n",
    "  * Models that don't accurately resemble their training data are **underfitted**.\n",
    "  * Models that are too similar to their training data (take the individual points too literally‚Äîdon't generalize well) are **overfitted**.\n",
    "  * Both underfitting and overfitting are problematic.\n",
    "* **Machine learning** is a fitting procedure, usually with very large datasets and very large numbers of parameters.\n",
    "* A **neural network** is currently the most successful kind of machine learning model.\n",
    "  * A neural network consists of layers of linear functions with many parameters sandwiched between non-linear functions.\n",
    "  * Optimizing a neural network involves tuning the parameters of the linear functions so that the whole model fits the training data.\n",
    "  * **Deep learning** is a neural network with many layers (which became feasible about 10 years ago)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096ddee-ee95-4e34-8241-09d6912f701c",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c3791-857f-4ae9-b230-0bac7680f3c4",
   "metadata": {},
   "source": [
    "## What we'll do today"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d481dc-9ee3-42fa-bddf-5bbdcb37cbc4",
   "metadata": {},
   "source": [
    "Short discussion of categorical variables with the penguins.\n",
    "\n",
    "A more detailed look at text-based data using the complete works of Shakespeare.\n",
    "\n",
    "Build an autocomplete engine, learning a little about SQL and databases along the way.\n",
    "\n",
    "Talk about the similarities and differences between our autocomplete engine and large language models like ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7edd08-aec3-468b-8258-04d70d1b279d",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b88531-734a-43ce-a4d5-bf0b75497260",
   "metadata": {},
   "source": [
    "## Categorical variables among the penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2eaf8-e86f-4f3d-8c15-38b5597ccfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c924fa-4c15-4319-80e9-40a54e3ea7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv(\"data/penguins.csv\")\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a38362-5a35-4ac0-bb98-ade1db3f3a75",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc234428-5485-4b6f-829a-d864d5b20366",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins[[\"species\", \"island\", \"sex\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48883ef7-fd35-4687-bef5-94635ce875a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins[\"species\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad74b8-e738-4945-80bc-a8a025e349ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins[\"island\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cee03d-4ff8-4f8b-903d-927c5f04ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins[\"sex\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d436e06c-885c-43f2-97fe-1290c67c00b5",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe2242a-fa09-4786-9fac-de92e29984cf",
   "metadata": {},
   "source": [
    "Many (not all!) machine learning models require inputs and outputs to be numerical. How can we do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e7f53-8c9e-40c2-b3eb-1eab9150147b",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0066f0dc-0932-43ec-8db2-966e501fc2eb",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fcc022-8e7a-4cfd-9176-4a95c1469d11",
   "metadata": {},
   "source": [
    "Associate a number to each category. We've already done this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f1a34-f846-4605-8d2f-23c9a1c99faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(penguins[\"species\"]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed7c17-18d6-4c65-85cc-13ddef91b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(penguins[\"island\"]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9339c8b-34d0-4665-8a6c-1de669e59448",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(penguins[\"sex\"]).codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893cb178-7cfc-4585-a852-c7624437843b",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3755f63-1740-4ebb-95ea-d3a4c7f0e59c",
   "metadata": {},
   "source": [
    "Notice that this plot is using a numerical relationship among Adelie, Gentoo, and Chinstrap to give the horizontal axis an order (Adelie first, then Gentoo, then Chinstrap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed754d-06d7-4d92-9b51-5aa38cee8f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins[\"species\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c77fd-7ab4-4bc7-88a8-5bc3dc50eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(penguins[\"species\"], penguins[\"island\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddbbd8b-2b69-40d5-8154-3dc12cb487dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "matrix = ax.matshow(pd.crosstab(penguins[\"species\"], penguins[\"island\"]).values)\n",
    "fig.colorbar(matrix, label=\"number of penguins\")\n",
    "\n",
    "ax.set_xticks([0, 1, 2], [\"Biscoe\", \"Dream\", \"Torgersen\"])\n",
    "ax.set_yticks([0, 1, 2], [\"Adelie\", \"Chinstrap\", \"Gentoo\"])\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbdbffc-83f4-4dd2-a136-a01ca8844af1",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76629eb-842a-4a6d-9e9a-5634b4a30826",
   "metadata": {},
   "source": [
    "The disadvantage of this method is that the order is not meaningful‚Äîit's something we made up‚Äîand a machine learning model might optimize for it.\n",
    "\n",
    "It's an invitation to overfitting (which can be controlled, but still)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9683d9-04f9-4df6-98f8-6d79b2f38938",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049cfc54-1fe3-4a9a-a5a2-590ac6d50440",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d94c84-11e9-4a6c-86b3-2db6ed41c444",
   "metadata": {},
   "source": [
    "Create a dimension for each value of a categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15921d-b453-4fd1-a77d-0f50fc9c2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_penguins = pd.get_dummies(penguins.dropna(), columns=[\"species\", \"island\", \"sex\"])\n",
    "expanded_penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878315d2-a3fb-49b2-9bb5-b30cc841ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "sex2D = expanded_penguins[[\"sex_female\", \"sex_male\"]].values\n",
    "\n",
    "# scatter a little, so we can see overlapping points\n",
    "sex2D = sex2D.astype(np.float64) + np.random.normal(0, 0.05, (len(expanded_penguins), 2))\n",
    "\n",
    "ax.scatter(sex2D[:, 0], sex2D[:, 1], marker=\".\")\n",
    "\n",
    "ax.set_xlim(-0.3, 1.3)\n",
    "ax.set_ylim(-0.3, 1.3)\n",
    "ax.set_xlabel(\"sex_female\")\n",
    "ax.set_ylabel(\"sex_male\")\n",
    "ax.axhline(0, color=\"gray\", ls=\":\")\n",
    "ax.axvline(0, color=\"gray\", ls=\":\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ee8e9-a2b0-4912-b185-0ae73bea994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "island3D = expanded_penguins[[\"island_Biscoe\", \"island_Dream\", \"island_Torgersen\"]].values\n",
    "\n",
    "# scatter a little, so we can see overlapping points\n",
    "island3D = island3D.astype(np.float64) + np.random.normal(0, 0.05, (len(expanded_penguins), 3))\n",
    "\n",
    "ax.scatter(island3D[:, 0], island3D[:, 1], island3D[:, 2], marker=\".\")\n",
    "\n",
    "ax.set_xlabel(\"Biscoe\")\n",
    "ax.set_ylabel(\"Dream\")\n",
    "ax.set_zlabel(\"Torgersen\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a069ae6-ecdc-46e4-a236-d2309a702254",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4b317-4545-4641-b8ae-df714f54c21a",
   "metadata": {},
   "source": [
    "The disadvantages of this method are that\n",
    "\n",
    "* we quickly end up with a lot of dimensions, which uses more memory and computation time, and\n",
    "* all the values between and beyond 0 and 1 are meaningless.\n",
    "\n",
    "But if you can afford it, it's a robust way to make models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30075a76-6d43-40da-adcd-cb14acc3f3ce",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046cc6b9-7f8f-4243-b018-5c6a34e81957",
   "metadata": {},
   "source": [
    "## Dataset: the complete works of Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9f28d-7ca0-4a42-a8e2-3b7780f914f8",
   "metadata": {},
   "source": [
    "This used to be a big dataset, used to illustrate large storage devices, like in [this definition of CD-ROM](https://vintageapple.org/apple_ii/pdf/Apple_IIGS__Ownwers_Guide_1986.pdf) from 1986:\n",
    "\n",
    "<img src=\"img/shakespeare-a-big-dataset.png\" width=\"600\">\n",
    "\n",
    "Now it's small enough to easily load in JupyterLite but is still big enough to be interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0e5f10-bc12-46fc-ba20-de8f8b8a329e",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f8767d-18fb-4b0c-907e-eab6720f13d3",
   "metadata": {},
   "source": [
    "This file comes from Project Gutenberg, [ebook #100](https://www.gutenberg.org/ebooks/100):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e692285-26fe-4e53-9cbd-95ea094627c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/shakespeare.txt\") as file:\n",
    "    corpus = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2cd8d-2291-4550-b468-56bc01368edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59238d63-7e71-4976-b412-4df3c5b5f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79440957-226f-4d21-add6-ee5ec85ead69",
   "metadata": {},
   "source": [
    "5.36 MB (a whole laser disk, apparently)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69243038-8b18-4bf1-95cf-10846f219be9",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41439cb7-f5f1-466c-9006-966543672fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus[100000:101000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ba72c-2114-44d3-a833-89e824cf1f61",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626cb458-2dfd-4c5d-8e01-6fe22e7439a5",
   "metadata": {},
   "source": [
    "What distinct characters does it have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc451885-2555-4260-a0a2-6083e6f9d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84875aef-4b40-4c1d-aead-e04e847fcca3",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f359c-752f-4d3a-96e6-61790753fd59",
   "metadata": {},
   "source": [
    "## How often is \"t\" followed by \"h\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02184a24-fc46-4dbe-94b1-14484447814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_character = []\n",
    "next_character = []\n",
    "for i in range(len(corpus) - 1):\n",
    "    first_character.append(corpus[i])\n",
    "    next_character.append(corpus[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d05d4c-6609-4ac0-9227-22ef581be17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_character[100414:100439]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ebf782-ccb3-4d5f-83ca-23ce4ece03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_character[100414:100439]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5805a-68d8-4d41-960a-4a1847dbd81c",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563e70f-ec58-44fc-872a-5ff978a71df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.crosstab(first_character, next_character, rownames=[\"first\"], colnames=[\"next\"])\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4603180-edd3-4c78-b211-c54abe9c9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_columns = pairs[pairs.sum(axis=0).sort_values(ascending=False).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d055a7-b3b5-4784-9646-dca076591d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_both = sorted_by_columns.loc[sorted_by_columns.sum(axis=1).sort_values(ascending=False).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250301d0-4d0a-49da-b6aa-dada4039356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7268d0-8d10-476e-bfac-c7b1e8650951",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "matrix = ax.matshow(sorted_by_both.values)\n",
    "\n",
    "ax.set_xticks(range(len(sorted_by_both.index)), sorted_by_both.index)\n",
    "ax.set_yticks(range(len(sorted_by_both.columns)), sorted_by_both.columns)\n",
    "\n",
    "ax.set_xlim(-0.5, 25.5)\n",
    "ax.set_ylim(-0.5, 25.5)\n",
    "ax.set_ylabel(\"first character\")\n",
    "ax.set_xlabel(\"next character\")\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2045102-6a91-4d9a-8fcb-d57466656506",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36858464-3be9-41e0-acf2-9f7e392e9463",
   "metadata": {},
   "source": [
    "The bright spots are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f193d-729b-445f-8b1b-181dd7afe69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.loc[\"e\", \" \"]   # e followed by space (at the end of a word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5903a8-3e8a-416a-b0cd-9e496946198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.loc[\" \", \"t\"]   # space followed by t (at the beginning of a word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb444e91-2654-4648-9132-a8a97a2f00b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.loc[\"t\", \"h\"]   # t followed by h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82fa19-da0a-4f82-b7c6-5f3312dedade",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.loc[\".\", \" \"]   # period followed by space (at the end of a sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b83f40-5435-46aa-94f0-27d5341a44ac",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650cac4-b72d-4fc4-9501-30839d99505d",
   "metadata": {},
   "source": [
    "## Sequence of characters ‚Üí sequence of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea2662-9030-4454-9de5-ff6d7f90c12c",
   "metadata": {},
   "source": [
    "We could build a per-letter autocomplete algorithm that would see \"t\" and suggest \"h\", but it wouldn't produce interesting text.\n",
    "\n",
    "It gets more interesting if we do this at the word level.\n",
    "\n",
    "The first step of **parsing**, an analysis of human-readable text, is **tokenizing** the input: turning raw characters into **tokens**.\n",
    "\n",
    "Why \"tokens\" and not \"words\"? Some of our tokens will be punctuation marks, so that when your autocomplete algorithm sees `hark` it can suggest a token like `!`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15f17c-4e07-4a0e-8668-4bc683d34404",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03dfc1-ed92-430c-b384-c3a5f967d654",
   "metadata": {},
   "source": [
    "**Regular expressions** or **regex** is a mini-language for recognizing strings and parts of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b332a30-9e4c-4fec-b5f8-71d565073390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c72543-5ca1-4442-af57-e5638ea68869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#               \"‚Äô\" for \"thou be‚Äôst\" and \"-\" for \"a-foot\"       multi-digit number as a token\n",
    "#                olden-time (and French) letters     ü°ì    \"&c.\"  ü°ì  \"+\" matches sequences of at least 1 character\n",
    "#        capital and lowercase letters       ü°ì       ü°ì     ü°ì     ü°ì  ü°ì   match any single character that is not (^) a space\n",
    "#                                  ü°ì         ü°ì       ü°ì     ü°ì     ü°ì  ü°ì   ü°ì\n",
    "recognize_token = re.compile(\"([A-Za-z√Ä√Ü√á√â√†√¢√¶√ß√®√©√™√´√Æ≈ì‚Äô-]+|&c\\.|[0-9]+|[^ ])\")\n",
    "#                            ü°ë                          ü°ë    ü°ë      ü°ë\n",
    "#              \"(\" and \")\" form a group               \"|\" means \"or\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a3774-ef34-4793-960a-636149cca0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognize_token.findall(\"Dost thou be‚Äôst 007 tok√´ns, &c.?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968d6b1-ea41-42d0-af3a-eea5897d58cf",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94cc2a7-11a7-4d1b-84ed-eb7aadbf0c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in recognize_token.finditer(corpus):\n",
    "    token = match.group(0)\n",
    "    print(repr(token))\n",
    "    if token == \".\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a99f24-39dc-4924-acae-b4a25d633777",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a0ae9-7163-4ea9-a2a2-562decb6413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for match in recognize_token.finditer(corpus):\n",
    "    tokens.append(match.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335e092-e7b4-49be-8a0d-99b63f799a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77627f43-4869-4e49-9503-8ef99f936841",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88638040-b7f2-4987-ab0a-0941facdba85",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac71590-b514-44d6-89ac-74b88309fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da30d44-72ce-4754-9471-a72b57bfc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26e7b0-d199-439f-947a-07ed1fa653f8",
   "metadata": {},
   "source": [
    "Instead of a 103√ó103 table of \"first\", \"next\" pairs, this would be a 36775√ó36775 table. Too big!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4bcdc5-531d-464e-b9e8-e15149f96d62",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537db7ff-6fa2-493c-bc51-bc8e1c1dc52e",
   "metadata": {},
   "source": [
    "## SQL, the language of table manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2311070e-d321-4297-a6d5-d2d42c771bc4",
   "metadata": {},
   "source": [
    "Just as **regular expression** is a mini-language that we can call from Python to handle strings, **SQL** is a mini-language to deal with tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acab08f-6311-44b4-ab17-7c884a248157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc085d0-2804-47f0-9c08-eea3099a6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(\":memory:\")\n",
    "db.execute(\"CREATE TABLE works(title TEXT, type TEXT, characters INTEGER, year_low INTEGER, year_high INTEGER)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece55759-ceb4-41d4-850a-d441feda868a",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ebf05-0c8e-4602-9252-27a45fdee0b7",
   "metadata": {},
   "source": [
    "(Don't take the following data too seriously; I got it from ChatGPT.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb6f63-b413-46ad-9d6b-eee7b77fe1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_python = [\n",
    "    [\"The Sonnets\", \"poetry\", None, 1609, 1609],\n",
    "    [\"All‚Äôs Well that Ends Well\", \"comedy\", 23, 1604, 1605],\n",
    "    [\"The Tragedy of Antony and Cleopatra\", \"tragedy\", 42, 1606, 1606],\n",
    "    [\"As You Like It\", \"comedy\", 27, 1599, 1600],\n",
    "    [\"The Comedy of Errors\", \"comedy\", 18, 1594, 1594],\n",
    "    [\"The Tragedy of Coriolanus\", \"tragedy\", 30, 1608, 1608],\n",
    "    [\"Cymbeline\", \"mixed\", 20, 1609, 1610],\n",
    "    [\"The Tragedy of Hamlet, Prince of Denmark\", \"tragedy\", 30, 1599, 1601],\n",
    "    [\"The First Part of King Henry the Fourth\", \"history\", 25, 1596, 1597],\n",
    "    [\"The Second Part of King Henry the Fourth\", \"history\", 25, 1597, 1598],\n",
    "    [\"The Life of King Henry the Fifth\", \"history\", 30, 1599, 1599],\n",
    "    [\"The First Part of Henry the Sixth\", \"history\", 40, 1590, 1592],\n",
    "    [\"The Second Part of King Henry the Sixth\", \"history\", 30, 1590, 1591],\n",
    "    [\"The Third Part of King Henry the Sixth\", \"history\", 30, 1591, 1591],\n",
    "    [\"King Henry the Eighth\", \"history\", 30, 1612, 1613],\n",
    "    [\"The Life and Death of King John\", \"history\", 20, 1596, 1596],\n",
    "    [\"The Tragedy of Julius Caesar\", \"tragedy\", 40, 1599, 1599],\n",
    "    [\"The Tragedy of King Lear\", \"tragedy\", 20, 1605, 1606],\n",
    "    [\"Love‚Äôs Labour‚Äôs Lost\", \"comedy\", 23, 1594, 1595],\n",
    "    [\"The Tragedy of Macbeth\", \"tragedy\", 20, 1606, 1606],\n",
    "    [\"Measure for Measure\", \"comedy\", 20, 1603, 1604],\n",
    "    [\"The Merchant of Venice\", \"comedy\", 22, 1596, 1597],\n",
    "    [\"The Merry Wives of Windsor\", \"comedy\", 24, 1597, 1597],\n",
    "    [\"A Midsummer Night‚Äôs Dream\", \"comedy\", 21, 1595, 1596],\n",
    "    [\"Much Ado About Nothing\", \"comedy\", 23, 1598, 1599],\n",
    "    [\"The Tragedy of Othello, the Moor of Venice\", \"tragedy\", 21, 1603, 1604],\n",
    "    [\"Pericles, Prince of Tyre\", \"late romance\", 20, 1607, 1608],\n",
    "    [\"King Richard the Second\", \"history\", 20, 1595, 1595],\n",
    "    [\"King Richard the Third\", \"history\", 30, 1592, 1593],\n",
    "    [\"The Tragedy of Romeo and Juliet\", \"tragedy\", 20, 1595, 1595],\n",
    "    [\"The Taming of the Shrew\", \"comedy\", 16, 1590, 1592],\n",
    "    [\"The Tempest\", \"late romance\", 12, 1610, 1611],\n",
    "    [\"The Life of Timon of Athens\", \"tragedy\", 20, 1605, 1606],\n",
    "    [\"The Tragedy of Titus Andronicus\", \"tragedy\", 25, 1591, 1592],\n",
    "    [\"Troilus and Cressida\", \"mixed\", 30, 1601, 1602],\n",
    "    [\"Twelfth Night; or, What You Will\", \"comedy\", 18, 1601, 1602],\n",
    "    [\"The Two Gentlemen of Verona\", \"comedy\", 20, 1589, 1593],\n",
    "    [\"The Two Noble Kinsmen\", \"comedy\", 20, 1613, 1614],\n",
    "    [\"The Winter‚Äôs Tale\", \"comedy\", 21, 1609, 1611],\n",
    "    [\"A Lover‚Äôs Complaint\", \"poetry\", None, 1609, 1609],\n",
    "    [\"The Passionate Pilgrim\", \"poetry\", None, 1599, 1599],\n",
    "    [\"The Phoenix and the Turtle\", \"poetry\", None, 1601, 1601],\n",
    "    [\"The Rape of Lucrece\", \"poetry\", 2, 1594, 1594],\n",
    "    [\"Venus and Adonis\", \"poetry\", 2, 1593, 1593],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7f00f-6b04-4a12-884c-124e69b0733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.executemany(\"INSERT INTO works VALUES(?, ?, ?, ?, ?)\", data_in_python)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b4554-621d-41b6-9357-bb5f4107d8f6",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa97843-3aca-42e3-9654-71b28ce77a35",
   "metadata": {},
   "source": [
    "Although SQL will be more computationally efficient for what we want to do, it doesn't have a convenient way to print out and look at a table.\n",
    "\n",
    "But we can dump it into Pandas and view it there.\n",
    "\n",
    "`SELECT` means select columns (not rows), and `*` means \"everything\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a30ef5-7ddc-4958-a05d-8934291e74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT * FROM works\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c514d-1aa8-447c-8c91-676a60e499b3",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ca1f5-6099-435d-98e7-bdfe75b29e69",
   "metadata": {},
   "source": [
    "Mathematical manipulations, such as `year_uncertainty` = `year_high - year_low`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0787c-c2a4-40fd-a56d-6eb204283b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT title, year_high - year_low AS year_uncertainty FROM works\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52012a34-7b9b-4cf0-a6f8-6e37ade1917e",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ed47b-c6a7-490d-b09e-954a7bbf4441",
   "metadata": {},
   "source": [
    "`WHERE` selects rows (not columns) by value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72974e1-68a7-4f8a-846f-46a4c899e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT * FROM works WHERE type = 'tragedy'\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd51b6-4079-4c9d-8602-4b2f1af984f9",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e29e54-a3db-43ad-8c57-b437e75aaec5",
   "metadata": {},
   "source": [
    "`GROUP BY` aggregates the data, such as counting, adding, and finding the minimum or maximum, in groups of rows with the same value of some variable (`type` in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ca32a-bd26-4ae6-b0eb-99e838c197ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT type, COUNT(*) AS number, SUM(characters), MIN(year_low), MAX(year_high) FROM works GROUP BY type\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e9da37-eca9-428f-b672-d82b7f6b5cbb",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948ba1b3-5510-40be-b1e7-cdd718c5ec73",
   "metadata": {},
   "source": [
    "## Fie Upon Thee, Autocomplete!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d71a61-9054-4a43-adf7-3c953576aadf",
   "metadata": {},
   "source": [
    "### 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b50fd-6f3c-485d-81fc-c74e2a66013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = []\n",
    "for i in range(len(tokens) - 1):\n",
    "    ngrams.append([tokens[i], tokens[i + 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671de6b-5d5a-4193-8f6d-5fa211399017",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\"CREATE TABLE ngrams2(word1 TEXT, word2 TEXT)\")\n",
    "db.executemany(\"INSERT INTO ngrams2 VALUES(?, ?)\", ngrams)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1222964-eca0-4e9f-b6a3-ff66d0fe07a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT * from ngrams2\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fae0418-c186-4d89-9a68-2c9ad50f475b",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdae570-2d5b-4baf-acab-b78e6828ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\"CREATE TABLE ngrams2_count AS SELECT word1, word2, COUNT(*) AS count FROM ngrams2 GROUP BY word1, word2 ORDER BY -count\")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8927043-062b-4e83-9c32-00e7830e9508",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT * from ngrams2_count\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef8a7d2-f313-47fd-a84e-bc1f5fdb6673",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610974b-2bab-4d48-bb99-784f14185341",
   "metadata": {},
   "source": [
    "Querying the database table as an autocomplete engine: what's the most likely token after `prompt`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6a0ab-ca40-4617-bdd1-c05058fdc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be5c38-0515-43d3-86f6-89732b4a3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = db.execute(\"SELECT word1, word2, count FROM ngrams2_count WHERE word1=?\", prompt).fetchmany(30)\n",
    "completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbcf3c1-2d87-4ad8-9683-7e66ebbfef1d",
   "metadata": {},
   "source": [
    "Okay, these are some good matches, but we want more context for larger prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af058014-e77f-4c29-9526-d344d9121639",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883aa984-fa86-4a70-bea2-0e2e04fdbbf6",
   "metadata": {},
   "source": [
    "### 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea28c2-8819-4de9-a596-05f881e79483",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = []\n",
    "for i in range(len(tokens) - 2):\n",
    "    ngrams.append([tokens[i], tokens[i + 1], tokens[i + 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875c02d-047e-457f-86fb-d57d8c05527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\"CREATE TABLE ngrams3(word1 TEXT, word2 TEXT, word3 TEXT)\")\n",
    "db.executemany(\"INSERT INTO ngrams3 VALUES(?, ?, ?)\", ngrams)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e43d57-5fbd-4990-81f0-81b8a52768ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\"CREATE TABLE ngrams3_count AS SELECT word1, word2, word3, COUNT(*) AS count FROM ngrams3 GROUP BY word1, word2, word3 ORDER BY -count\")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb0bfa3-fb7f-4909-916a-9a9fc7187c96",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca88520-768e-4956-88be-9a3268957210",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"O\", \"Romeo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8dfbd4-6738-4ac8-addc-0b068f85d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = db.execute(\"SELECT word1, word2, word3, count FROM ngrams3_count WHERE word1=? AND word2=?\", prompt).fetchmany(30)\n",
    "completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b102d86-f1f3-4222-a435-dec146b53f1b",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77834fd2-cf59-4a8b-8514-403140e9ff7f",
   "metadata": {},
   "source": [
    "If we take the first of these, where does it lead us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef5014-fe1f-412b-b625-4693c55c0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = prompt + [completions[0][2]]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5703db-98d7-4f87-89a7-9379c286865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = db.execute(\"SELECT word1, word2, word3, count FROM ngrams3_count WHERE word1=? AND word2=?\", history[-2:]).fetchmany(30)\n",
    "completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fe6c32-ff8f-4412-afec-922243d5d3bb",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897e91d-5b88-4e6d-b35f-cf37c3326055",
   "metadata": {},
   "source": [
    "Keep doing it! Run this cell repeatedly with control-enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c6a02-0a15-4902-b0e7-89d007daee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = history + [completions[0][2]]\n",
    "completions = db.execute(\"SELECT word1, word2, word3, count FROM ngrams3_count WHERE word1=? AND word2=?\", history[-2:]).fetchmany(30)\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54910b4f-ac25-4d36-a035-dcacdd660a61",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffb06bf-d15f-4198-807c-2cd9717e4bea",
   "metadata": {},
   "source": [
    "Okay, maybe we shouldn't always take the most common completion. Maybe we should vary it up and randomly pick from the top 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253fadfd-1ef7-47bd-a6c6-249ba0ff6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\"O\", \"Romeo\"]\n",
    "\n",
    "def autocomplete(history, number):\n",
    "    completions = db.execute(\"SELECT word1, word2, word3, count FROM ngrams3_count WHERE word1=? AND word2=?\", history[-2:]).fetchmany(number)\n",
    "    index = np.random.randint(0, len(completions))\n",
    "    return history + [completions[index][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018280f-f6d7-4205-a9fb-9e809db61b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autocomplete(history, 5)\n",
    "\n",
    "for token in history:\n",
    "    if token in \",;:‚Äî.!?‚Äú‚Äù‚Äò&\":\n",
    "        prefix = \"\"\n",
    "    else:\n",
    "        prefix = \" \"\n",
    "    print(prefix + token, end=\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4009567-d284-479a-8c0b-cf2f10cdefa8",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb25ff-c501-481d-9b77-76e26fc24188",
   "metadata": {},
   "source": [
    "### 10-minute exercise: 4-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a3fa2-3d16-4d4f-b955-7d2557cdb5ab",
   "metadata": {},
   "source": [
    "Make it better by building a database (model) of completions that are 4 tokens long!\n",
    "\n",
    "If you need to delete a table because of a mistake, use the `DROP TABLE <name>` syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648bbca-105f-420c-843e-976fb85d38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\"DROP TABLE ngrams2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a8bfc-62ba-496b-9ce1-c9c073f536e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\"DROP TABLE ngrams2_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f905c-7450-4de9-8279-b19a2ddbd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\"DROP TABLE ngrams3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c54eb-4e09-44f3-9e70-88280346e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\"DROP TABLE ngrams3_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34b8689-b314-4b27-8f3b-989cb912a66d",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12e10e-6496-4dea-a4f9-b9331f574916",
   "metadata": {},
   "source": [
    "After an `INSERT INTO`, you need to `db.commit`, and after a `SELECT`, you have to `fetchmany`, as in the examples above.\n",
    "\n",
    "**Hint:** Copy the cells of the 3-gram case and modify it to make 4-grams.\n",
    "\n",
    "Form groups of 2 or 3 and work together!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c863eb4-906f-420c-b86b-afab92240724",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6861f5-84bb-432f-987a-79009c3be01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = []\n",
    "for i in range(len(tokens) - 3):\n",
    "    ngrams.append([tokens[i], tokens[i + 1], tokens[i + 2], tokens[i + 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406dd178-5c52-42cb-bf24-6eaada852b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ngrams4 table and fill it with the ngrams data.\n",
    "print(\"???\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4136a3a-1375-4d2f-96eb-2bad6217e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a GROUP BY operation to count the number of times each unique (word1, word2, word3, word4) combination is seen.\n",
    "print(\"???\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ddd90d-1be4-4421-b02f-3f82ae921766",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\"O\", \"Romeo\", \",\"]\n",
    "\n",
    "# Extend the autocomplete function to return (word1, word2, word3, word4) rows in which (word1, word2, word3) are the last 3 in the history.\n",
    "def autocomplete(history, number):\n",
    "    print(\"???\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4cc88c-3dbe-4139-8f73-2a9bda884c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autocomplete(history, 5)\n",
    "\n",
    "for token in history:\n",
    "    if token in \",;:‚Äî.!?‚Äú‚Äù‚Äò&\":\n",
    "        prefix = \"\"\n",
    "    else:\n",
    "        prefix = \" \"\n",
    "    print(prefix + token, end=\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa530a-e23c-48d2-9a3d-d2d0ebe64b22",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df58fc6-2fa3-4213-b81a-dfe12cc0966a",
   "metadata": {},
   "source": [
    "### Solution (do not peek!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77114d-b137-45da-960f-82e742bceee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = []\n",
    "for i in range(len(tokens) - 3):\n",
    "    ngrams.append([tokens[i], tokens[i + 1], tokens[i + 2], tokens[i + 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc29aaa-9796-414e-b38d-b4fc8cc4d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\"CREATE TABLE ngrams4(word1 TEXT, word2 TEXT, word3 TEXT, word4 TEXT)\")\n",
    "db.executemany(\"INSERT INTO ngrams4 VALUES(?, ?, ?, ?)\", ngrams)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84625545-6c7e-47ae-9b76-c7fe22502a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(\"CREATE TABLE ngrams4_count AS SELECT word1, word2, word3, word4, COUNT(*) AS count FROM ngrams4 GROUP BY word1, word2, word3, word4 ORDER BY -count\")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baedaf68-9bf7-4c2d-ae9d-0afa3e9aed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\"O\", \"Romeo\", \",\"]\n",
    "\n",
    "def autocomplete(history, number):\n",
    "    completions = db.execute(\"SELECT word1, word2, word3, word4, count FROM ngrams4_count WHERE word1=? AND word2=? AND word3=?\", history[-3:]).fetchmany(number)\n",
    "    index = np.random.randint(0, len(completions))\n",
    "    return history + [completions[index][3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c68bb-b456-4576-a838-7d18944b64b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autocomplete(history, 5)\n",
    "\n",
    "for token in history:\n",
    "    if token in \",;:‚Äî.!?‚Äú‚Äù‚Äò&\":\n",
    "        prefix = \"\"\n",
    "    else:\n",
    "        prefix = \" \"\n",
    "    print(prefix + token, end=\"\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
