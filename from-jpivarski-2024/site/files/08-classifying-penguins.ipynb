{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8871badc-fde3-41b5-84bd-c6a781034edb",
   "metadata": {},
   "source": [
    "# Classifying penguins with a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ce2a7-b6bd-49f7-8491-1f417cec81f1",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26903f8-547d-4062-9e92-8dff5186d644",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setting up to classify penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c62bf7-7159-4992-bc46-cbee2f710114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "import sklearn.neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fb42e-3ce3-478f-b6ff-b291b961f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv(\"data/penguins.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960aab6a-db68-4d34-965e-16b49ad0772f",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b956b8-bfda-4224-8142-9da91c02fc85",
   "metadata": {},
   "source": [
    "Just like the classification tasks that you just worked on, let's classify penguin species by measurements of their bills.\n",
    "\n",
    "<img src=\"img/culmen_depth.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac894149-3191-441f-8674-2d40372e3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "penguins[penguins[\"species\"] == \"Adelie\"].plot.scatter(\"bill_length_mm\", \"bill_depth_mm\", color=\"blue\", ax=ax)\n",
    "penguins[penguins[\"species\"] == \"Gentoo\"].plot.scatter(\"bill_length_mm\", \"bill_depth_mm\", color=\"orange\", ax=ax)\n",
    "penguins[penguins[\"species\"] == \"Chinstrap\"].plot.scatter(\"bill_length_mm\", \"bill_depth_mm\", color=\"green\", ax=ax)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ecad8-fda3-47d6-b07b-ccafa619dafd",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426dcb9e-8d7f-4c33-a915-db5043527f14",
   "metadata": {},
   "source": [
    "First complication: `\"Adelie\"`, `\"Gentoo\"`, and `\"Chinstrap\"` are strings, but neural networks return numbers.\n",
    "\n",
    "But all we care about are distinctions between strings, such as\n",
    "\n",
    "```python\n",
    "\"Adelie\" == \"Adelie\"   # and\n",
    "\"Adelie\" != \"Gentoo\"\n",
    "```\n",
    "\n",
    "So we'll replace the strings with numbers—a distinct number for each distinct string.\n",
    "\n",
    "In Pandas, this is the `pd.Categorical` data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22678555-07f0-45b2-b1d0-8c72b6e6f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(penguins[\"species\"]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a108f-67ac-4d82-bf30-823def0fbdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins[\"species_code\"] = pd.Categorical(penguins[\"species\"]).codes\n",
    "penguins[[\"species\", \"species_code\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131944d-80fb-4baf-8beb-557b89f1594b",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfeaa1-29d3-4edb-a2c2-d735f0a77004",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = penguins.dropna()[[\"bill_length_mm\", \"bill_depth_mm\"]].values\n",
    "desired_output = penguins.dropna()[\"species_code\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4471acb1-a65d-4e52-bcc1-dfb7c130d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4360dc5-992e-4ce0-ba4b-266cb299236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae35384-d25b-4ca7-9099-2db2408cd6ec",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e2f0a-0194-47d6-a84b-b484312099ad",
   "metadata": {},
   "source": [
    "Second complication: neural networks are slow to train if the input values are far from ‒1 through 1.\n",
    "\n",
    "So we'll scale them (subtract and multiply by constants) to put them in that range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3ece8-54c6-4c56-8367-c160b0cde905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c00a948-1b1e-4d92-8f20-90fddb2886ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler((-1, 1)).fit(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802f019-17b4-424b-9993-fbb53d68dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_input_data = scaler.transform(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5debf4-dc73-4b20-b460-9c2f73d6544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(scaled_input_data[:, 0], scaled_input_data[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b87211-8e79-4643-be7a-09eb1c481108",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf28477-a6a6-4505-9105-d9772ff1825e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## No hidden layers: (mostly) linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c558b-9cf8-4030-bc42-cf52f8fb3b5e",
   "metadata": {},
   "source": [
    "First, we'll train a neural network with no hidden layers, which makes it a purely linear model.\n",
    "\n",
    "It's called \"logistic classification\" because the linear fit has to be transformed to return probabilities between 0 and 1:\n",
    "\n",
    "$$P_0 = \\mbox{classify as adelie}$$\n",
    "\n",
    "$$P_1 = \\mbox{classify as gentoo}$$\n",
    "\n",
    "$$P_2 = \\mbox{classify as chinstrap}$$\n",
    "\n",
    "with $P_0 + P_1 + P_2 = 1$. The output of the linear fit has to be passed through a function called [softmax](https://en.wikipedia.org/wiki/Softmax_function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168307f4-db4e-4622-98df-f390c241f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = sklearn.neural_network.MLPClassifier(solver=\"lbfgs\", activation=\"logistic\", hidden_layer_sizes=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d40ba3-ed31-449e-b3ce-cb0bba55d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.fit(scaled_input_data, desired_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a961414f-0b84-480c-8d4e-4fd69252675b",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3698e3-bfa7-4c45-b5ab-123cd79b1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(13, 4))\n",
    "\n",
    "xmin, xmax = -1, 1\n",
    "ymin, ymax = -1, 1\n",
    "\n",
    "background_x, background_y = np.meshgrid(np.linspace(xmin, xmax, 100), np.linspace(ymin, ymax, 100))\n",
    "\n",
    "probabilities = logistic_regression.predict_proba(np.column_stack([background_x.ravel(), background_y.ravel()]))\n",
    "\n",
    "ax0.contourf(background_x, background_y, probabilities[:, 0].reshape(background_x.shape))\n",
    "ax1.contourf(background_x, background_y, probabilities[:, 1].reshape(background_x.shape))\n",
    "ax2.contourf(background_x, background_y, probabilities[:, 2].reshape(background_x.shape))\n",
    "\n",
    "for ax in [ax0, ax1, ax2]:\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlabel(\"scaled bill length\")\n",
    "\n",
    "ax0.set_ylabel(\"scaled bill depth\")\n",
    "\n",
    "ax0.set_title(\"probability of adelie\")\n",
    "ax1.set_title(\"probability of gentoo\")\n",
    "ax2.set_title(\"probability of chinstrap\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f5a1d2-2914-4fef-8241-3938891ac49d",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80d9b8-0923-4b64-8c1e-2f49c0d7cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_everything(model):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    \n",
    "    xmin, xmax = -1, 1\n",
    "    ymin, ymax = -1, 1\n",
    "    \n",
    "    background_x, background_y = np.meshgrid(np.linspace(xmin, xmax, 100), np.linspace(ymin, ymax, 100))\n",
    "    \n",
    "    probabilities = model.predict_proba(np.column_stack([background_x.ravel(), background_y.ravel()]))\n",
    "    \n",
    "    ax.contour(background_x, background_y, probabilities[:, 0].reshape(background_x.shape), [0.5])\n",
    "    ax.contour(background_x, background_y, probabilities[:, 1].reshape(background_x.shape), [0.5])\n",
    "    ax.contour(background_x, background_y, probabilities[:, 2].reshape(background_x.shape), [0.5])\n",
    "    \n",
    "    ax.scatter(*scaled_input_data[desired_output == 0].T, color=\"blue\")\n",
    "    ax.scatter(*scaled_input_data[desired_output == 1].T, color=\"orange\")\n",
    "    ax.scatter(*scaled_input_data[desired_output == 2].T, color=\"green\")\n",
    "    \n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlabel(\"scaled bill length\")\n",
    "    ax.set_ylabel(\"scaled bill depth\")\n",
    "\n",
    "draw_everything(logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d249d-fcee-4c3b-95e1-63410698c26c",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd7a20-a883-49f0-b389-a4bb326e4c0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Now with hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e056729b-34a5-475c-82fa-f39adeb05948",
   "metadata": {},
   "source": [
    "Already pretty good. Let's add some hidden layers to make this a real neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23e849-a004-44d5-b991-2e446c6895b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network1 = sklearn.neural_network.MLPClassifier(solver=\"lbfgs\", activation=\"logistic\", hidden_layer_sizes=(10, 10), max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87466087-f4dc-4374-85e1-446200ddbc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network1.fit(scaled_input_data, desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e4fc89-f187-4e92-9498-30890c6c6b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_everything(neural_network1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8e194-d32c-47e9-b8bd-5aca2332b722",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c73e46-c724-47ab-8e17-a9f107e15194",
   "metadata": {},
   "source": [
    "That's too loose! It's overfitting like crazy!\n",
    "\n",
    "Let's add regularization to force the model to be simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b515a-c76b-4bf9-bcef-a26b44bff1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network2 = sklearn.neural_network.MLPClassifier(solver=\"lbfgs\", activation=\"logistic\", hidden_layer_sizes=(10, 10), max_iter=1000, alpha=0.03)\n",
    "\n",
    "neural_network2.fit(scaled_input_data, desired_output)\n",
    "\n",
    "draw_everything(neural_network2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1e6b97-a502-4cf0-b8d2-18b076ebc0f2",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a09370-b9c6-4a42-9e1e-a3c73d4b198b",
   "metadata": {},
   "source": [
    "Side-note: neural networks and other advanced machine learning models aren't always necessary!\n",
    "\n",
    "For this problem, I would consider a logistic regression good enough. Adding hidden layers only introduces problems with overfitting and non-determinism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb47a3b3-3ebc-463f-a7ad-944df0596179",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4eb420-d061-475c-8bc1-b401026a7ced",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Conclusion for day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45482fc1-8faa-4cb0-8668-f9f9ece31388",
   "metadata": {},
   "source": [
    "How regular _should_ it be?\n",
    "\n",
    "If the model is too strict—too few parameters, too strongly regularized, underfit—then it doesn't describe or predict well.\n",
    "\n",
    "If the model is too loose—too many parameters, too weakly regularized, overfit—then it is a restatement of the training data and makes wacky predictions in regions with no training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05e50f-3d7e-4306-a004-4fa438824653",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8fb98e-6f60-40df-b3db-40a4db0adee4",
   "metadata": {},
   "source": [
    "**Tomorrow:** language models!\n",
    "\n",
    "For fun, here's sample output from [my first attempt](https://github.com/jpivarski/rnn-oz) at a language model 6 years ago:\n",
    "\n",
    "> Then manderunt thee. I's anf leus, for and as to mope not thal se the Caid will the wale. \"I trop iclusers and Willy age and preed geach duppeny.\n",
    ">\n",
    "> \"I doble and the primman forsed the Ellarke coup?\" Realk.\n",
    ">\n",
    "> \"There lookna'u cere them chimed was neerid.\n",
    ">\n",
    "> \"Younway the arous afrithy Stonsad. \"Ws?\"\n",
    ">\n",
    "> \"On. But'm dee poas the gad now ulterwoth the lorked the where were if Dorothy, \"untle lecking the hes got wook to care wors.\n",
    ">\n",
    "> \"Ic intameed him godlyed,\" is dich buttly. As pigle.\n",
    ">\n",
    "> \"Me?\" a dexn hander upen this slieve \"angolst,\" facked a more srough copenting his then the tuvp Is strome it it, and likned to Ozquere mane so nol hud of to suf awe grissand, hom hal as for thingn wish witley, and wondents ucherthy brome byinged inknest's clawirs, she bot the briced to peinon\" \"I dpor. out the motlond honky what hen with frow thin't dyole thes teen then man he sugnit.\n",
    ">\n",
    "> \"Num, he chan she dices. I waykel of caply Lood abreaklulres frisk and elewal, Igredled sto liow je a shirut, a do no her at was al ouly a wessed to falded anknes you, and a thister blecel of she lady. Suppen hows indiedat of his, who fien. \"Thing, ald greps a dotsores.\n",
    "\n",
    "Yours will be better!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
